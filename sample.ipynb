{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# This is a sample Jupyter Notebook\n",
    "\n",
    "Below is an example of a code cell. \n",
    "Put your cursor into the cell and press Shift+Enter to execute it and select the next one, or click 'Run Cell' button.\n",
    "\n",
    "Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "\n",
    "To learn more about Jupyter Notebooks in PyCharm, see [help](https://www.jetbrains.com/help/pycharm/ipython-notebook-support.html).\n",
    "For an overview of PyCharm, go to Help -> Learn IDE features or refer to [our documentation](https://www.jetbrains.com/help/pycharm/getting-started.html)."
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:30:23.502236Z",
     "start_time": "2024-09-08T14:29:53.614363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages')\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from urllib.parse import urljoin, urlparse\n",
    "from lxml import html\n",
    "import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import openpyxl\n",
    "import tkinter\n",
    "from tkinter import simpledialog\n",
    "from tkinter import filedialog\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import random\n",
    "\n",
    "base_url = simpledialog.askstring(\"Input\", \"Enter the NHS Jobs URL (without page number):\")\n",
    "base_url += \"pg=\"  #add \"&page=\" part to URL\n",
    "num_pages_str = simpledialog.askstring(\"Input\", \"Enter the number of pages you want to extract:\")\n",
    "num_pages = int(num_pages_str) if num_pages_str is not None else 1\n",
    "# Define the XPath expressions for data extraction\n",
    "xpaths = {\n",
    "    \"employer_name\": '//*[@id=\"hj-job-summary\"]/div/div/div/dl[2]/dd[1]',\n",
    "    \"job_title\": '//*[@id=\"hj-enquiry-html\"]/div/dl/dd[2]',\n",
    "    \"name\": '//*[@id=\"hj-enquiry-html\"]/div/dl/dd[1]',\n",
    "    \"number\": '//*[@id=\"hj-enquiry-html\"]/div/dl/dd[4]',\n",
    "    \"email\": '//*[@id=\"hj-enquiry-html\"]/div/dl/dd[3]',\n",
    "    'area recruiting for': '//*[@id=\"hj-job-summary\"]/div/div/div/dl[1]/dd[1]',\n",
    "    'job recruiting for': '//*[@id=\"hj-job\"]/div/div[1]/h2',\n",
    "    'recruitment close date': '//*[@id=\"hj-job-summary\"]/div/div/div/dl[2]/dd[7]',\n",
    "    'contract': '//*[@id=\"hj-job-summary\"]/div/div/div/dl[1]/dd[3]',\n",
    "    'reference': '//*[@id=\"hj-job-summary\"]/div/div/div/dl[1]/dd[5]',\n",
    "    'Hours': '//*[@id=\"hj-job-summary\"]/div/div/div/dl[1]/dd[4]',\n",
    "    'address line 1': '//*[@id=\"hj-job-summary\"]/div/div/div/dl[2]/dd[3]',\n",
    "    'town': '//*[@id=\"hj-job-summary\"]/div/div/div/dl[2]/dd[4]',\n",
    "    'salary': '//*[@id=\"hj-job-summary\"]/div/div/div/dl[2]/dd[5]',\n",
    "    'Band': '//*[@id=\"hj-job-summary\"]/div/div/div/dl[1]/dd[2]',\n",
    "    'personal spec': '//*[@id=\"hj-job-role-requirement\"]/div',\n",
    "    'job description': '//*[@id=\"hj-job-advert\"]'\n",
    "\n",
    "\n",
    "}\n",
    "dataframes = [] # Initialize an empty list to store DataFrames\n",
    "\n",
    "session = requests.Session()\n",
    "session.max_redirects = 2  # Sets a limit on the number of redirects\n",
    "# Goes through url, adds page numbers and extracts xpath data from all ads on those pages\n",
    "for page in range(1, num_pages + 1):\n",
    "    url = base_url + str(page)\n",
    "    response = session.get(url)\n",
    "    if response.status_code == 200:\n",
    "        print(f\" successfully located\" +url + '/'+num_pages_str)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        job_adverts = soup.find_all(\"a\", href=True, attrs={\"href\": \"/job/UK/\"})\n",
    "\n",
    "        for advert in job_adverts:\n",
    "            advert_relative_url = advert[\"href\"]\n",
    "            if \"/job/UK/\" in advert_relative_url:\n",
    "                advert_url = urljoin(base_url, advert_relative_url)\n",
    "                url_parts = urlparse(advert_url)\n",
    "                if url_parts.scheme:\n",
    "                    try:\n",
    "                        advert_response = session.get(advert_url)\n",
    "                        advert_response.raise_for_status()\n",
    "                        advert_tree = html.fromstring(advert_response.text)\n",
    "                        advert_data = {}\n",
    "                        for key, xpath in xpaths.items():\n",
    "                            elements = advert_tree.xpath(xpath)\n",
    "                            if elements:\n",
    "                                advert_data[key] = elements[0].text_content()\n",
    "                            else:\n",
    "                                print(f\"No specified XPath elements detected for {key}\")\n",
    "                        dataframes.append(pd.DataFrame(advert_data, index=[0]))\n",
    "                    except requests.exceptions.HTTPError as http_err:\n",
    "                        print(f\"HTTP error occurred for URL {advert_url}: {http_err}\")\n",
    "                    except Exception as err:\n",
    "                        print(f\"An error occurred for URL {advert_url}: {err}\")\n",
    "                else:\n",
    "                    print(f\"Invalid URL: {advert_url}\")\n",
    "# Concatenate dataframe\n",
    "if dataframes:\n",
    "    final_dataframe = pd.concat(dataframes, ignore_index=True)\n",
    "    # Setup the root Tkinter window\n",
    "    root = tkinter.Tk()\n",
    "    root.withdraw()  # Hide the root window\n",
    "    # Ask the user to select the save location and filename using file explorer\n",
    "    current_datetime = datetime.datetime.now()\n",
    "    default_filename = f\"job_adverts_{current_datetime.strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
    "    file_path = filedialog.asksaveasfilename(\n",
    "        initialdir=os.path.expanduser(\"~/Desktop\"),  # Set initial directory to the Desktop\n",
    "        title=\"Select file\",\n",
    "        filetypes=((\"Excel files\", \"*.xlsx\"), (\"All files\", \"*.*\")),\n",
    "        defaultextension=\".xlsx\",\n",
    "        initialfile=default_filename\n",
    "    )\n",
    "    # Check if a file path was provided (i.e., user didn't cancel the dialog)\n",
    "    if file_path:\n",
    "        # Save the DataFrame to an Excel file at the specified path\n",
    "        final_dataframe.to_excel(file_path, index=False)\n",
    "        print(f\"File saved successfully at {file_path}\")\n",
    "    else:\n",
    "        print(\"File save cancelled.\")\n",
    "else:\n",
    "    simpledialog.messagebox.showinfo(\"Completion\", \"No data extracted.\")\n"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +=: 'NoneType' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 24\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mrandom\u001B[39;00m\n\u001B[0;32m     23\u001B[0m base_url \u001B[38;5;241m=\u001B[39m simpledialog\u001B[38;5;241m.\u001B[39maskstring(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInput\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEnter the NHS Jobs URL (without page number):\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 24\u001B[0m base_url \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpg=\u001B[39m\u001B[38;5;124m\"\u001B[39m  \u001B[38;5;66;03m#add \"&page=\" part to URL\u001B[39;00m\n\u001B[0;32m     25\u001B[0m num_pages_str \u001B[38;5;241m=\u001B[39m simpledialog\u001B[38;5;241m.\u001B[39maskstring(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInput\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEnter the number of pages you want to extract:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     26\u001B[0m num_pages \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(num_pages_str) \u001B[38;5;28;01mif\u001B[39;00m num_pages_str \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m1\u001B[39m\n",
      "\u001B[1;31mTypeError\u001B[0m: unsupported operand type(s) for +=: 'NoneType' and 'str'"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
